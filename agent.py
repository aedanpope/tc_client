
from map import Map

Mode = Map(
    train = 0, # Explore and train the network.
    test = 1, # Test the current optimal performance of the network.
)

class Settings:
  # How noisy to print debug output. 0 = none, 30 = max
  verbosity = None

  mode = Mode.train
  hyperparameters = None

# Represents a whole mini-battle.
class Battle:
  stages = None
  is_end = None
  is_won = None
  trained = False

  def __init__(self):
    self.stages = []
    self.is_end = False


  def add_stage(self, stage):
    self.stages.append(stage)
    if stage.is_end:
      self.is_end = True
      self.is_won = stage.is_won

  def num_stages(self):
    return len(self.stages)

  def size(self):
    return len(self.stages)

  def get_stage(self, index):
    return self.stages[index]
  def __getitem__(self, key):
      return self.stages.__getitem__(key)

  def to_str(self):
    return ("Battle {" +
            "stages: " + str(self.stages) +
            ", is_end: " + str(self.is_end) +
            ", is_won: " + str(self.is_won) +
            "}")
  def __str__(self):
    return self.to_str()
  def __repr__(self):
    return self.to_str()


# Represents a single frame in a battle.
# Assumes one unit per side.
class Stage:
  # Ctor vars.
  # state = None
  friendly_life = None # Friendly HP in the stage
  enemy_life = None # Enemy HP in the stage
  is_end = None
  is_won = None
  friendly_unit = None
  enemy_unit = None

  # Vars added later:
  inp = None # Input into the neural network.
  q = None # The Q generated by the network from the inp, which determined the action if we didn't explore.
  action = None # The action that was taken on the state.
  # The reward we attribute to taking the action on the input. Changes over time as we learn more about
  # the consequences of having taken that action on that input.
  reward = None

  def __init__(self, state):
    self.friendly_unit = 0 if not state.friendly_units else state.friendly_units.values()[0]
    self.enemy_unit = 0 if not state.enemy_units else state.enemy_units.values()[0]

    # Derived values:
    self.friendly_life = 0 if not state.friendly_units else state.friendly_units.values()[0].get_life()
    self.enemy_life = 0 if not state.enemy_units else state.enemy_units.values()[0].get_life()
    self.is_end = state.battle_ended
    self.is_won = state.battle_won

    # self.is_end = self.friendly_life == 0 or self.enemy_life == 0
    # if self.is_end:
    #   self.is_won = self.friendly_life > 0
    # self.reward = 0

  def to_str(self):
    return ("Stage {" +
            "inp: " + str(self.inp) +
            ", q: " + str(self.q) +
            ", action: " + str(self.action) +
            ", friendly_life: " + str(self.friendly_life) +
            ", enemy_life: " + str(self.enemy_life) +
            ", is_end: " + str(self.is_end) +
            ", is_won: " + str(self.is_won) +
            "}")
  def __str__(self):
    return self.to_str()
  def __repr__(self):
    return self.to_str()
